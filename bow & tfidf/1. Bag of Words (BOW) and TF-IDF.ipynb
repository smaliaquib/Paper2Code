{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1731b08",
   "metadata": {},
   "source": [
    "## Bag Of Words (BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9b868b",
   "metadata": {},
   "source": [
    "#### Advantages\n",
    "\n",
    "* **Simple to understand and implement:** The BoW model is straightforward to understand and implement, making it accessible even to those new to NLP\n",
    "\n",
    "* **Scalability:** BoW can scale well to large datasets and vocabularies, especially when using sparse matrix representations\n",
    "\n",
    "* **Versatility:** BoW can be used for a wide range of NLP tasks, including sentiment analysis, text classification, document clustering, and more\n",
    "\n",
    "#### Disadvantages\n",
    "\n",
    "* **Loss of word order and context:** BoW disregards the order of words and their context within the text, treating each document as a \"bag\" of words. This can lead to a loss of valuable semantic information, especially in tasks where word order and context are important (e.g., language modeling, sequence-to-sequence tasks).\n",
    "\n",
    "* **Sparsity:** BoW representations are typically sparse, especially when dealing with large vocabularies or documents with many unique words. This can lead to high-dimensional feature spaces and computational challenges.\n",
    "\n",
    "* **No consideration of word semantics:** BoW treats each word as a separate feature and does not consider the semantic relationships between words. This can result in a lack of semantic understanding in the representation, leading to suboptimal performance in tasks requiring deeper linguistic understanding.\n",
    "\n",
    "* **Vocabulary size:** BoW representations can grow large with the size of the vocabulary, which may pose challenges in terms of memory and computational resources, especially when dealing with very large datasets or vocabularies.\n",
    "\n",
    "* **Insensitive to word frequency:** BoW treats all words equally in terms of their frequency, which may not be suitable for tasks where word frequency or importance plays a significant role (e.g., keyword extraction, summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db50856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "# Sample collection of text documents\n",
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1392c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the sparse matrix to a dense array for easier inspection (not recommended for large datasets)\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Get the feature names (words) corresponding to the columns in the BoW matrix\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c036502b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  document  first  is  one  second  the  third  this\n",
       "text 1    0         1      1   1    0       0    1      0     1\n",
       "text 2    0         2      0   1    0       1    1      0     1\n",
       "text 3    1         0      0   1    1       0    1      1     1\n",
       "text 4    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db39d292",
   "metadata": {},
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2728ae1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowercase True: ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "lowercase False: ['And' 'Is' 'This' 'document' 'first' 'is' 'one' 'second' 'the' 'third'\n",
      " 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "vectorizer_lowercase = CountVectorizer(lowercase=True)\n",
    "vectorizer_no_lowercase = CountVectorizer(lowercase=False)\n",
    "\n",
    "vectorizer_lowercase.fit_transform(documents)\n",
    "vectorizer_no_lowercase.fit_transform(documents)\n",
    "\n",
    "print(f'lowercase True: {vectorizer_lowercase.get_feature_names_out()}')\n",
    "print(f'lowercase False: {vectorizer_no_lowercase.get_feature_names_out()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a63c24",
   "metadata": {},
   "source": [
    "### Preprocessor\n",
    "\n",
    "* CountVectorizer, the preprocessor parameter allows you to specify a function that will be applied to each document before tokenization and processing. This function can be used for tasks such as cleaning or preprocessing the text data before it is tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3557fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with custom preprocessor:\n",
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Custom preprocessor function to convert text to lowercase\n",
    "def custom_preprocessor(text):\n",
    "    return text.lower()\n",
    "\n",
    "vectorizer_preprocessor = CountVectorizer(preprocessor=custom_preprocessor)\n",
    "\n",
    "# Fit and transform the documents using CountVectorizer with custom preprocessor\n",
    "X_preprocessor = vectorizer_preprocessor.fit_transform(documents)\n",
    "feature_names_preprocessor = vectorizer_preprocessor.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names with custom preprocessor:\")\n",
    "print(feature_names_preprocessor)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995adc2c",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5086b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07de8ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.' '?' 'and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aquib\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def custom_tokenizer(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7104afb",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "763dba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stp = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d858c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document' 'first' 'one' 'second' 'third']\n"
     ]
    }
   ],
   "source": [
    "custom_stopwords = ['is', 'the', 'and', 'this']\n",
    "\n",
    "# vectorizer = CountVectorizer(stop_words='english')\n",
    "# vectorizer = CountVectorizer(stop_words=custom_stopwords)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=stp)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1c631",
   "metadata": {},
   "source": [
    "### Strip Accent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779dce6f",
   "metadata": {},
   "source": [
    "**The strip_accents parameter in the CountVectorizer class of scikit-learn is used to specify whether to remove accents and perform normalization on the text data before tokenization. Accents, also known as diacritical marks, are additional symbols added to letters in various languages to indicate different pronunciations or meanings.**\n",
    "\n",
    "**Here's why strip_accents is used and its significance:**\n",
    "\n",
    "* ***Normalization:*** Text data often contains accented characters, especially in languages like French, Spanish, German, etc. By default, strip_accents is set to None, meaning that no normalization is performed. However, setting it to 'unicode' or 'ascii' can help normalize the text by removing accents and converting accented characters to their ASCII or Unicode equivalents, respectively.\n",
    "\n",
    "* ***Uniformity:*** Removing accents helps achieve uniformity in the text data. For example, \"café\" and \"cafe\" would be treated as the same word after removing accents, which can be important for text processing tasks such as text classification, clustering, or information retrieval.\n",
    "\n",
    "* ***Reduced Vocabulary Size:*** By removing accents and converting accented characters to their ASCII or Unicode equivalents, the vocabulary size may be reduced, leading to a more compact and efficient representation of the text data.\n",
    "\n",
    "* ***Improved Model Performance:*** In some cases, removing accents can improve the performance of text-based machine learning models by reducing the complexity of the vocabulary and focusing on the essential information in the text.\n",
    "\n",
    "**However, it's essential to note that stripping accents may not always be necessary or desirable, especially in languages where accents carry semantic meaning (e.g., French, Spanish). Therefore, the choice of whether to use strip_accents and which value to set it to ('unicode', 'ascii', or None) depends on the specific requirements of the text processing task and the characteristics of the text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5694869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with strip_accents='ascii':\n",
      "['cafe' 'eleve' 'resume' 'role']\n",
      "\n",
      "Feature names with strip_accents='unicode':\n",
      "['cafe' 'eleve' 'resume' 'role']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"café\",\n",
    "    \"élève\",\n",
    "    \"rôle\",\n",
    "    \"résumé\"\n",
    "]\n",
    "vectorizer_ascii = CountVectorizer(strip_accents='ascii')\n",
    "vectorizer_unicode = CountVectorizer(strip_accents='unicode')\n",
    "\n",
    "X_ascii = vectorizer_ascii.fit_transform(documents)\n",
    "X_unicode = vectorizer_unicode.fit_transform(documents)\n",
    "\n",
    "feature_names_ascii = vectorizer_ascii.get_feature_names_out()\n",
    "feature_names_unicode = vectorizer_unicode.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names with strip_accents='ascii':\")\n",
    "print(feature_names_ascii)\n",
    "print()\n",
    "\n",
    "print(\"Feature names with strip_accents='unicode':\")\n",
    "print(feature_names_unicode)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a05f43",
   "metadata": {},
   "source": [
    "### Decode Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1534aa",
   "metadata": {},
   "source": [
    "**The decode_error parameter in scikit-learn's CountVectorizer class specifies how decoding errors encountered during text processing are handled. This parameter is relevant when dealing with text data that needs to be decoded from a specific encoding, such as UTF-8.**\n",
    "\n",
    "**Here's what the decode_error parameter does:**\n",
    "\n",
    "*    ***decode_error='strict':*** This is the default behavior. It means that if an error occurs during decoding (e.g., invalid byte sequence), a UnicodeDecodeError exception will be raised, and the processing of the text will stop.\n",
    "\n",
    "*    ***decode_error='ignore':*** If this value is set, decoding errors will be silently ignored, and the problematic characters will be skipped. This can be useful if you want to continue processing the text data even if some parts are not decodable.\n",
    "\n",
    "*    ***decode_error='replace':*** With this setting, any characters that cannot be decoded will be replaced with a placeholder character (usually the Unicode replacement character U+FFFD). This option ensures that the text can still be processed, albeit with some loss of information.\n",
    "\n",
    "**Choosing the appropriate value for decode_error depends on your specific use case and the nature of the text data you're working with. If you're confident that your text data is encoded correctly and you want to be notified of any decoding errors, you can stick with the default 'strict' behavior. On the other hand, if your data might contain encoding issues and you want to continue processing it despite potential errors, you can use 'ignore' or 'replace' to handle decoding errors more gracefully.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3d12b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with decode_error='strict':\n",
      "['and' 'byte' 'document' 'first' 'has' 'invalid' 'is' 'one' 'the' 'third'\n",
      " 'this']\n",
      "Transformed documents with decode_error='strict':\n",
      "[[0 0 1 1 0 0 1 0 1 0 1]\n",
      " [0 1 1 0 1 1 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 1 1 1 1 1]]\n",
      "\n",
      "Feature names with decode_error='ignore':\n",
      "['and' 'byte' 'document' 'first' 'has' 'invalid' 'is' 'one' 'the' 'third'\n",
      " 'this']\n",
      "Transformed documents with decode_error='ignore':\n",
      "[[0 0 1 1 0 0 1 0 1 0 1]\n",
      " [0 1 1 0 1 1 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 1 1 1 1 1]]\n",
      "\n",
      "Feature names with decode_error='replace':\n",
      "['and' 'byte' 'document' 'first' 'has' 'invalid' 'is' 'one' 'the' 'third'\n",
      " 'this']\n",
      "Transformed documents with decode_error='replace':\n",
      "[[0 0 1 1 0 0 1 0 1 0 1]\n",
      " [0 1 1 0 1 1 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# b'this document has \\xff invalid byte'\n",
    "\n",
    "# Sample collection of text documents with a decoding error\n",
    "documents = [\n",
    "    b'this is the first document',            # Valid UTF-8 encoded bytes\n",
    "    b'this document has invalid byte',  # Invalid byte sequence (decoding error)\n",
    "    b'and this is the third one'             # Valid UTF-8 encoded bytes\n",
    "]\n",
    "\n",
    "# Initialize CountVectorizer with decode_error='strict' (default)\n",
    "vectorizer_strict = CountVectorizer(decode_error='strict')\n",
    "X_strict = vectorizer_strict.fit_transform(documents)\n",
    "\n",
    "# Initialize CountVectorizer with decode_error='ignore'\n",
    "vectorizer_ignore = CountVectorizer(decode_error='ignore')\n",
    "X_ignore = vectorizer_ignore.fit_transform(documents)\n",
    "\n",
    "# Initialize CountVectorizer with decode_error='replace'\n",
    "vectorizer_replace = CountVectorizer(decode_error='replace')\n",
    "X_replace = vectorizer_replace.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (vocabulary) for each vectorizer\n",
    "feature_names_strict = vectorizer_strict.get_feature_names_out()\n",
    "feature_names_ignore = vectorizer_ignore.get_feature_names_out()\n",
    "feature_names_replace = vectorizer_replace.get_feature_names_out()\n",
    "\n",
    "# Print the feature names and transformed documents for each vectorizer\n",
    "print(\"Feature names with decode_error='strict':\")\n",
    "print(feature_names_strict)\n",
    "print(\"Transformed documents with decode_error='strict':\")\n",
    "print(X_strict.toarray())\n",
    "print()\n",
    "\n",
    "print(\"Feature names with decode_error='ignore':\")\n",
    "print(feature_names_ignore)\n",
    "print(\"Transformed documents with decode_error='ignore':\")\n",
    "print(X_ignore.toarray())\n",
    "print()\n",
    "\n",
    "print(\"Feature names with decode_error='replace':\")\n",
    "print(feature_names_replace)\n",
    "print(\"Transformed documents with decode_error='replace':\")\n",
    "print(X_replace.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d5c65",
   "metadata": {},
   "source": [
    "### Using NGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdab5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b0d7a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>and this</th>\n",
       "      <th>document</th>\n",
       "      <th>document is</th>\n",
       "      <th>first</th>\n",
       "      <th>first document</th>\n",
       "      <th>is</th>\n",
       "      <th>is the</th>\n",
       "      <th>is this</th>\n",
       "      <th>one</th>\n",
       "      <th>...</th>\n",
       "      <th>the</th>\n",
       "      <th>the first</th>\n",
       "      <th>the second</th>\n",
       "      <th>the third</th>\n",
       "      <th>third</th>\n",
       "      <th>third one</th>\n",
       "      <th>this</th>\n",
       "      <th>this document</th>\n",
       "      <th>this is</th>\n",
       "      <th>this the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  and this  document  document is  first  first document  is  \\\n",
       "text 1    0         0         1            0      1               1   1   \n",
       "text 2    0         0         2            1      0               0   1   \n",
       "text 3    1         1         0            0      0               0   1   \n",
       "text 4    0         0         1            0      1               1   1   \n",
       "\n",
       "        is the  is this  one  ...  the  the first  the second  the third  \\\n",
       "text 1       1        0    0  ...    1          1           0          0   \n",
       "text 2       1        0    0  ...    1          0           1          0   \n",
       "text 3       1        0    1  ...    1          0           0          1   \n",
       "text 4       0        1    0  ...    1          1           0          0   \n",
       "\n",
       "        third  third one  this  this document  this is  this the  \n",
       "text 1      0          0     1              0        1         0  \n",
       "text 2      0          0     1              1        0         0  \n",
       "text 3      1          1     1              0        1         0  \n",
       "text 4      0          0     1              0        0         1  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "# print(vectorizer.vocabulary_)\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74cd7c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and this</th>\n",
       "      <th>document is</th>\n",
       "      <th>first document</th>\n",
       "      <th>is the</th>\n",
       "      <th>is this</th>\n",
       "      <th>second document</th>\n",
       "      <th>the first</th>\n",
       "      <th>the second</th>\n",
       "      <th>the third</th>\n",
       "      <th>third one</th>\n",
       "      <th>this document</th>\n",
       "      <th>this is</th>\n",
       "      <th>this the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and this  document is  first document  is the  is this  \\\n",
       "text 1         0            0               1       1        0   \n",
       "text 2         0            1               0       1        0   \n",
       "text 3         1            0               0       1        0   \n",
       "text 4         0            0               1       0        1   \n",
       "\n",
       "        second document  the first  the second  the third  third one  \\\n",
       "text 1                0          1           0          0          0   \n",
       "text 2                1          0           1          0          0   \n",
       "text 3                0          0           0          1          1   \n",
       "text 4                0          1           0          0          0   \n",
       "\n",
       "        this document  this is  this the  \n",
       "text 1              0        1         0  \n",
       "text 2              1        0         0  \n",
       "text 3              0        1         0  \n",
       "text 4              0        0         1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "# print(vectorizer.vocabulary_)\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0930141e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and this</th>\n",
       "      <th>and this is</th>\n",
       "      <th>document is</th>\n",
       "      <th>document is the</th>\n",
       "      <th>first document</th>\n",
       "      <th>is the</th>\n",
       "      <th>is the first</th>\n",
       "      <th>is the second</th>\n",
       "      <th>is the third</th>\n",
       "      <th>is this</th>\n",
       "      <th>...</th>\n",
       "      <th>the second document</th>\n",
       "      <th>the third</th>\n",
       "      <th>the third one</th>\n",
       "      <th>third one</th>\n",
       "      <th>this document</th>\n",
       "      <th>this document is</th>\n",
       "      <th>this is</th>\n",
       "      <th>this is the</th>\n",
       "      <th>this the</th>\n",
       "      <th>this the first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        and this  and this is  document is  document is the  first document  \\\n",
       "text 1         0            0            0                0               1   \n",
       "text 2         0            0            1                1               0   \n",
       "text 3         1            1            0                0               0   \n",
       "text 4         0            0            0                0               1   \n",
       "\n",
       "        is the  is the first  is the second  is the third  is this  ...  \\\n",
       "text 1       1             1              0             0        0  ...   \n",
       "text 2       1             0              1             0        0  ...   \n",
       "text 3       1             0              0             1        0  ...   \n",
       "text 4       0             0              0             0        1  ...   \n",
       "\n",
       "        the second document  the third  the third one  third one  \\\n",
       "text 1                    0          0              0          0   \n",
       "text 2                    1          0              0          0   \n",
       "text 3                    0          1              1          1   \n",
       "text 4                    0          0              0          0   \n",
       "\n",
       "        this document  this document is  this is  this is the  this the  \\\n",
       "text 1              0                 0        1            1         0   \n",
       "text 2              1                 1        0            0         0   \n",
       "text 3              0                 0        1            1         0   \n",
       "text 4              0                 0        0            0         1   \n",
       "\n",
       "        this the first  \n",
       "text 1               0  \n",
       "text 2               0  \n",
       "text 3               0  \n",
       "text 4               1  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,3))\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "# print(vectorizer.vocabulary_)\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab78b2e",
   "metadata": {},
   "source": [
    "### MIN MAX Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65057c8",
   "metadata": {},
   "source": [
    "**In the CountVectorizer class of scikit-learn, \"min_df\" and \"max_df\" are parameters used to control the vocabulary size by specifying the minimum and maximum document frequency of terms (words) in the documents. Here's what they mean**\n",
    "    \n",
    "* ***\"min_df\":*** Terms with a document frequency lower than min_df will be ignored in the vocabulary. For example, setting min_df=2 will exclude terms that appear in fewer than 2 documents.\n",
    "\n",
    "* ***\"max_df\":*** This parameter is useful for excluding terms that are too frequent and may not provide useful information for tasks like text classification or clustering. For example, setting max_df=0.8 will exclude terms that appear in more than 80% of the documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d33df335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with min_df=1, max_df=1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  document  first  is  one  second  the  third  this\n",
       "text 1    0         1      1   1    0       0    1      0     1\n",
       "text 2    0         2      0   1    0       1    1      0     1\n",
       "text 3    1         0      0   1    1       0    1      1     1\n",
       "text 4    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize CountVectorizer with different min_df and max_df values\n",
    "vectorizer_min_df1_max_df1 = CountVectorizer(min_df=1, max_df=1.0)\n",
    "vectorizer_min_df2_max_df1 = CountVectorizer(min_df=2, max_df=1.0)\n",
    "vectorizer_min_df1_max_df2 = CountVectorizer(min_df=1, max_df=0.75)  # max_df=0.75 means exclude terms appearing in more than 75% of documents\n",
    "\n",
    "# Fit and transform the documents using each vectorizer\n",
    "X_min_df1_max_df1 = vectorizer_min_df1_max_df1.fit_transform(documents)\n",
    "X_min_df2_max_df1 = vectorizer_min_df2_max_df1.fit_transform(documents)\n",
    "X_min_df1_max_df2 = vectorizer_min_df1_max_df2.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (vocabulary)\n",
    "feature_names_min_df1_max_df1 = vectorizer_min_df1_max_df1.get_feature_names_out()\n",
    "feature_names_min_df2_max_df1 = vectorizer_min_df2_max_df1.get_feature_names_out()\n",
    "feature_names_min_df1_max_df2 = vectorizer_min_df1_max_df2.get_feature_names_out()\n",
    "\n",
    "# Display the feature names for each vectorizer\n",
    "print(\"Feature names with min_df=1, max_df=1:\")\n",
    "pd.DataFrame(data = X_min_df1_max_df1.toarray(), \n",
    "             columns=feature_names_min_df1_max_df1, \n",
    "             index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc8bea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with min_df=2, max_df=1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        document  first  is  the  this\n",
       "text 1         1      1   1    1     1\n",
       "text 2         2      0   1    1     1\n",
       "text 3         0      0   1    1     1\n",
       "text 4         1      1   1    1     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Feature names with min_df=2, max_df=1:\")\n",
    "pd.DataFrame(data = X_min_df2_max_df1.toarray(), \n",
    "             columns=feature_names_min_df2_max_df1, \n",
    "             index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aece3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with min_df=1, max_df=0.75:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  document  first  one  second  third\n",
       "text 1    0         1      1    0       0      0\n",
       "text 2    0         2      0    0       1      0\n",
       "text 3    1         0      0    1       0      1\n",
       "text 4    0         1      1    0       0      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Feature names with min_df=1, max_df=0.75:\")\n",
    "pd.DataFrame(data = X_min_df1_max_df2.toarray(), \n",
    "             columns=feature_names_min_df1_max_df2, \n",
    "             index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f9567",
   "metadata": {},
   "source": [
    "**Advantages of using min_df and max_df in CountVectorizer:**\n",
    "\n",
    "* ***Control over vocabulary size:*** You can control the size of the vocabulary by excluding terms that appear too rarely (min_df) or too frequently (max_df).\n",
    "\n",
    "* ****Noise reduction:*** Excluding terms with very low or very high document frequencies can help reduce noise in the data and improve the quality of the features used for modeling.\n",
    "\n",
    "* ****Improved generalization:*** By excluding terms that are too specific (low min_df) or too common (high max_df), you can improve the generalization performance of machine learning models.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "* ***Information loss:*** Excluding terms based on document frequency thresholds may result in the loss of potentially useful information, especially if the thresholds are set too aggressively.\n",
    "\n",
    "* ***Parameter tuning:*** Choosing appropriate values for min_df and max_df requires experimentation and tuning. Selecting optimal values may depend on the specific dataset and task.\n",
    "\n",
    "* ***Impact on model performance:*** Incorrectly setting min_df and max_df thresholds may adversely affect the performance of machine learning models, leading to suboptimal results.\n",
    "\n",
    "***In summary, while min_df and max_df offer control over the vocabulary size and can help improve the quality of features used for modeling, they require careful tuning and consideration to avoid information loss and ensure optimal model performance.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b62e1",
   "metadata": {},
   "source": [
    "### Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c087b0b",
   "metadata": {},
   "source": [
    "**In scikit-learn's CountVectorizer, the analyzer parameter determines whether the feature should be made of word or character n-grams.**\n",
    "\n",
    "* ***analyzer='word':*** This is the default value. It analyzes the input as a sequence of words. It splits the input into words based on white spaces and punctuation, and then forms features based on these words.\n",
    "\n",
    "* ***analyzer='char':*** It analyzes the input as a sequence of characters. It forms features based on character n-grams, where an n-gram is a contiguous sequence of n characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "697cb5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with analyzer='word':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  document  first  is  one  second  the  third  this\n",
       "text 1    0         1      1   1    0       0    1      0     1\n",
       "text 2    0         2      0   1    0       1    1      0     1\n",
       "text 3    1         0      0   1    1       0    1      1     1\n",
       "text 4    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize CountVectorizer with analyzer='word'\n",
    "vectorizer_word = CountVectorizer(analyzer='word')\n",
    "\n",
    "# Fit and transform the documents using CountVectorizer with 'word' analyzer\n",
    "X_word = vectorizer_word.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (vocabulary)\n",
    "feature_names_word = vectorizer_word.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names with analyzer='word':\")\n",
    "pd.DataFrame(data = X_word.toarray(), \n",
    "             columns=feature_names_word, \n",
    "             index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e32cb457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with analyzer='char':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>?</th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           .  ?  a  c  d  e  f  h  i  m  n  o  r  s  t  u\n",
       "text 1  4  1  0  0  1  1  2  1  2  3  1  1  1  1  3  4  1\n",
       "text 2  5  1  0  0  3  3  4  0  2  2  2  3  3  0  3  4  2\n",
       "text 3  5  1  0  1  0  2  2  0  3  3  0  2  1  1  2  3  0\n",
       "text 4  4  0  1  0  1  1  2  1  2  3  1  1  1  1  3  4  1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize CountVectorizer with analyzer='char'\n",
    "vectorizer_char = CountVectorizer(analyzer='char')\n",
    "\n",
    "# Fit and transform the documents using CountVectorizer with 'char' analyzer\n",
    "X_char = vectorizer_char.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (vocabulary)\n",
    "feature_names_char = vectorizer_char.get_feature_names_out()\n",
    "\n",
    "# Print the feature names and the transformed documents with 'char' analyzer\n",
    "print(\"Feature names with analyzer='char':\")\n",
    "pd.DataFrame(data = X_char.toarray(), \n",
    "             columns=feature_names_char, \n",
    "             index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc8329",
   "metadata": {},
   "source": [
    "**The text documents are processed using CountVectorizer with both 'word' and 'char' analyzers. With 'word' analyzer, the input is split into words based on white spaces and punctuation, while with 'char' analyzer, the input is split into character n-grams. The resulting feature matrices represent the occurrences of words and character n-grams in the documents, respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f095992",
   "metadata": {},
   "source": [
    "### Max Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b92997",
   "metadata": {},
   "source": [
    "**CountVectorizer, the max_features parameter specifies the maximum number of features (unique tokens or words) to be extracted from the text data. It controls the vocabulary size by limiting the number of features considered during the tokenization process.**\n",
    "\n",
    "**Here's what max_features does:**\n",
    "\n",
    "*   ***If max_features is an integer:*** The max_features parameter specifies the maximum number of features to be considered based on their frequency of occurrence in the corpus. The most frequent max_features features will be selected and used to create the vocabulary.\n",
    "\n",
    "*    ***If max_features is None (default):*** All features will be considered, and there is no limit on the number of features extracted.\n",
    "\n",
    "**Setting a value for max_features can be helpful in scenarios where you want to reduce the dimensionality of the feature space or improve computational efficiency by limiting the number of features considered.\n",
    "However, it's essential to note that specifying max_features may result in the loss of less frequent or informative features from the vocabulary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b098b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with max_features=5:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        document  first  is  the  this\n",
       "text 1         1      1   1    1     1\n",
       "text 2         2      0   1    1     1\n",
       "text 3         0      0   1    1     1\n",
       "text 4         1      1   1    1     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize CountVectorizer with max_features=5\n",
    "vectorizer_max_features = CountVectorizer(max_features=5)\n",
    "\n",
    "# Fit and transform the documents using CountVectorizer with max_features\n",
    "X_max_features = vectorizer_max_features.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (vocabulary)\n",
    "feature_names_max_features = vectorizer_max_features.get_feature_names_out()\n",
    "\n",
    "# Print the feature names and the transformed documents with max_features\n",
    "print(\"Feature names with max_features=5:\")\n",
    "pd.DataFrame(data = X_max_features.toarray(), \n",
    "             columns=feature_names_max_features, \n",
    "             index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaec228",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b127be",
   "metadata": {},
   "source": [
    "**CountVectorizer, the vocabulary parameter allows you to specify the vocabulary that the vectorizer should use when transforming the input data into feature vectors. The vocabulary is a mapping of terms (tokens or words) to feature indices in the resulting feature matrix.**\n",
    "\n",
    "*    ***If vocabulary is a mapping (e.g., dict):*** This mapping specifies the vocabulary that the vectorizer should use. The keys are the terms (tokens or words), and the values are the corresponding feature indices. Only the terms in the provided vocabulary will be considered during vectorization, and any terms not found in the vocabulary will be ignored.\n",
    "\n",
    "*    ***If vocabulary is an iterable (e.g., list, set):*** This iterable specifies the terms (tokens or words) that should be included in the vocabulary. The vectorizer will use these terms to create the vocabulary, and the resulting feature indices will be assigned accordingly.\n",
    "\n",
    "**Specifying a custom vocabulary using the vocabulary parameter can be useful in scenarios where you want to enforce a specific set of terms to be included in the feature matrix or when you want to map certain terms to specific feature indices.\n",
    "However, it's essential to note that using a custom vocabulary may result in missing features if some terms in the input data are not present in the specified vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64818124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with custom vocabulary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>this</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        this  is  the  document\n",
       "text 1     1   1    1         1\n",
       "text 2     1   1    1         2\n",
       "text 3     1   1    1         0\n",
       "text 4     1   1    1         1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a custom vocabulary\n",
    "custom_vocabulary = {\n",
    "    'this': 0,\n",
    "    'is': 1,\n",
    "    'the': 2,\n",
    "    'document': 3\n",
    "}\n",
    "\n",
    "# Initialize CountVectorizer with custom vocabulary\n",
    "vectorizer_vocabulary = CountVectorizer(vocabulary=custom_vocabulary)\n",
    "\n",
    "# Fit and transform the documents using CountVectorizer with custom vocabulary\n",
    "X_vocabulary = vectorizer_vocabulary.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (vocabulary)\n",
    "feature_names_vocabulary = vectorizer_vocabulary.get_feature_names_out()\n",
    "\n",
    "# Print the feature names and the transformed documents with custom vocabulary\n",
    "print(\"Feature names with custom vocabulary:\")\n",
    "pd.DataFrame(data = X_vocabulary.toarray(), \n",
    "             columns=feature_names_vocabulary, \n",
    "             index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3be86",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ef591",
   "metadata": {},
   "source": [
    "**CountVectorizer, the binary parameter is a boolean value that specifies whether the feature matrix should be binarized or not. When binary is set to True, the feature matrix will only contain binary values: 0 or 1. If a token (word) is present in a document, its corresponding feature value will be 1; otherwise, it will be 0.**\n",
    "\n",
    "Here's what binary does:\n",
    "\n",
    "* ***binary=True:*** The feature matrix will be binarized, meaning that it will only contain binary values. This is useful when you only want to represent the presence or absence of a token in a document, rather than its frequency.\n",
    "\n",
    "*  ***binary=False (default):*** The feature matrix will contain counts of tokens in each document, representing the frequency of each token.\n",
    "\n",
    "**Setting binary=True can be beneficial in certain scenarios, such as text classification tasks where the frequency of words is less relevant compared to their presence or absence in a document.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5d38ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with binary=True:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  document  first  is  one  second  the  third  this\n",
       "text 1    0         1      1   1    0       0    1      0     1\n",
       "text 2    0         1      0   1    0       1    1      0     1\n",
       "text 3    1         0      0   1    1       0    1      1     1\n",
       "text 4    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize CountVectorizer with binary=True\n",
    "vectorizer_binary = CountVectorizer(binary=True)\n",
    "vectorizer_nonbinary = CountVectorizer(binary=False)\n",
    "\n",
    "# Fit and transform the documents using CountVectorizer with binary=True\n",
    "X_binary = vectorizer_binary.fit_transform(documents)\n",
    "X_nonbinary = vectorizer_nonbinary.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (vocabulary)\n",
    "feature_names_binary = vectorizer_binary.get_feature_names_out()\n",
    "feature_names_nonbinary = vectorizer_nonbinary.get_feature_names_out()\n",
    "\n",
    "# Print the feature names and the transformed documents with binary=True\n",
    "print(\"Feature names with binary=True:\")\n",
    "pd.DataFrame(data = X_binary.toarray(), \n",
    "             columns=feature_names_binary, \n",
    "             index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b32333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names with binary=False:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  document  first  is  one  second  the  third  this\n",
       "text 1    0         1      1   1    0       0    1      0     1\n",
       "text 2    0         2      0   1    0       1    1      0     1\n",
       "text 3    1         0      0   1    1       0    1      1     1\n",
       "text 4    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Feature names with binary=False:\")\n",
    "pd.DataFrame(data = X_nonbinary.toarray(), \n",
    "             columns=feature_names_nonbinary, \n",
    "             index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b989c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ec3fb56",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents. It combines term frequency (TF), which measures the frequency of a term in a document, with inverse document frequency (IDF), which measures how unique or rare a term is across the entire document collection.\n",
    "\n",
    "#### Advantages\n",
    "\n",
    "* **Reflects word importance:** TF-IDF assigns higher scores to words that are important in a document while giving lower scores to common words. This helps capture the significance of words within a document.\n",
    "\n",
    "* **Handles common words:** TF-IDF automatically downweights common words that occur frequently across multiple documents, such as stopwords, by assigning them lower scores. This reduces the impact of noise in the data.\n",
    "\n",
    "* **Domain independence:** TF-IDF is relatively domain-independent and can be applied to various types of text data and domains without the need for extensive domain-specific knowledge or preprocessing.\n",
    "\n",
    "* **Simple and efficient:** Implementation of TF-IDF is straightforward, and it can be efficiently computed for large datasets using libraries like scikit-learn.\n",
    "\n",
    "#### Disadvantages\n",
    "\n",
    "* **Lack of semantic understanding:** TF-IDF does not consider the semantic meaning of words, treating them as independent units. As a result, it may not capture the semantic relationships between words and could miss important context.\n",
    "\n",
    "* **Ignores word order:** TF-IDF treats documents as bags of words, ignoring the order in which words appear within a document. This can lead to loss of sequential information, which may be important in certain applications like natural language processing tasks.\n",
    "\n",
    "* **Vulnerability to document length:** TF-IDF can be sensitive to document length, as longer documents may have higher raw term frequencies. Normalization techniques like sublinear TF scaling or length normalization can help mitigate this issue.\n",
    "\n",
    "* **Parameter sensitivity:** The effectiveness of TF-IDF can depend on the choice of parameters, such as the smoothing parameter for IDF and the normalization method for TF. Careful tuning of these parameters may be required for optimal performance in different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2bf52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7696775",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97ec132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c0329e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first        is       one    second       the  \\\n",
       "text 1  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "text 2  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
       "text 3  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "text 4  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "           third      this  \n",
       "text 1  0.000000  0.384085  \n",
       "text 2  0.000000  0.281089  \n",
       "text 3  0.511849  0.267104  \n",
       "text 4  0.000000  0.384085  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b6208",
   "metadata": {},
   "source": [
    "### Norm\n",
    "The norm parameter specifies the type of normalization applied to the TF-IDF matrix after calculating the term frequency-inverse document frequency (TF-IDF) scores.\n",
    "\n",
    "\n",
    "* **'l2' (default):** Each row of the TF-IDF matrix is normalized to have unit Euclidean norm (L2 norm). This means that the squared sum of the values in each row is equal to 1 after normalization.\n",
    "<br></br>\n",
    "* **'l1':** Each row of the TF-IDF matrix is normalized to have unit Manhattan norm (L1 norm). This means that the sum of the absolute values of the elements in each row is equal to 1 after normalization.\n",
    "<br></br>\n",
    "* **None:** No normalization is applied to the TF-IDF matrix. Each row of the TF-IDF matrix retains its original values without normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cbdbfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer with norm l2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first        is       one    second       the  \\\n",
       "text 1  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "text 2  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
       "text 3  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "text 4  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "           third      this  \n",
       "text 1  0.000000  0.384085  \n",
       "text 2  0.000000  0.281089  \n",
       "text 3  0.511849  0.267104  \n",
       "text 4  0.000000  0.384085  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(norm='l2')\n",
    "\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TfidfVectorizer with norm l2\")\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7faa131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer with norm l1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>0.263487</td>\n",
       "      <td>0.174399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260274</td>\n",
       "      <td>0.135822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0.219033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.219033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.219033</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>0.263487</td>\n",
       "      <td>0.174399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first        is       one    second       the  \\\n",
       "text 1  0.000000  0.213315  0.263487  0.174399  0.000000  0.000000  0.174399   \n",
       "text 2  0.000000  0.332260  0.000000  0.135822  0.000000  0.260274  0.135822   \n",
       "text 3  0.219033  0.000000  0.000000  0.114300  0.219033  0.000000  0.114300   \n",
       "text 4  0.000000  0.213315  0.263487  0.174399  0.000000  0.000000  0.174399   \n",
       "\n",
       "           third      this  \n",
       "text 1  0.000000  0.174399  \n",
       "text 2  0.000000  0.135822  \n",
       "text 3  0.219033  0.114300  \n",
       "text 4  0.000000  0.174399  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(norm='l1')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TfidfVectorizer with norm l1\")\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f13cc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer with norm None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.446287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first   is       one    second  the     third  \\\n",
       "text 1  0.000000  1.223144  1.510826  1.0  0.000000  0.000000  1.0  0.000000   \n",
       "text 2  0.000000  2.446287  0.000000  1.0  0.000000  1.916291  1.0  0.000000   \n",
       "text 3  1.916291  0.000000  0.000000  1.0  1.916291  0.000000  1.0  1.916291   \n",
       "text 4  0.000000  1.223144  1.510826  1.0  0.000000  0.000000  1.0  0.000000   \n",
       "\n",
       "        this  \n",
       "text 1   1.0  \n",
       "text 2   1.0  \n",
       "text 3   1.0  \n",
       "text 4   1.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TfidfVectorizer with norm None\")\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc86ab",
   "metadata": {},
   "source": [
    "### Use IDF\n",
    "\n",
    "* **When use_idf=True (default):** IDF reweighting is enabled, and the TF-IDF scores are computed as the product of term frequency (TF) and inverse document frequency (IDF). This means that words that are rare across the entire document collection will have higher IDF scores, leading to higher TF-IDF scores for those words in individual documents. IDF reweighting helps to downweight terms that occur frequently across multiple documents and upweight terms that are more specific or unique to individual documents.\n",
    "<br></br>\n",
    "* **When use_idf=False:** IDF reweighting is disabled, and the TF-IDF scores are computed only based on the term frequency (TF) of each term in the document. In this case, all terms are treated equally, regardless of their frequency in the entire document collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4d7e777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer with use_idf True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first        is       one    second       the  \\\n",
       "text 1  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "text 2  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
       "text 3  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "text 4  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "           third      this  \n",
       "text 1  0.000000  0.384085  \n",
       "text 2  0.000000  0.281089  \n",
       "text 3  0.511849  0.267104  \n",
       "text 4  0.000000  0.384085  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TfidfVectorizer with use_idf True\")\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fca7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer with use_idf False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first        is       one    second       the  \\\n",
       "text 1  0.000000  0.447214  0.447214  0.447214  0.000000  0.000000  0.447214   \n",
       "text 2  0.000000  0.707107  0.000000  0.353553  0.000000  0.353553  0.353553   \n",
       "text 3  0.408248  0.000000  0.000000  0.408248  0.408248  0.000000  0.408248   \n",
       "text 4  0.000000  0.447214  0.447214  0.447214  0.000000  0.000000  0.447214   \n",
       "\n",
       "           third      this  \n",
       "text 1  0.000000  0.447214  \n",
       "text 2  0.000000  0.353553  \n",
       "text 3  0.408248  0.408248  \n",
       "text 4  0.000000  0.447214  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=False)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TfidfVectorizer with use_idf False\")\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d63e0",
   "metadata": {},
   "source": [
    "### Smooth IDF\n",
    "\n",
    "Without smoothing (i.e., when smooth_idf=False), the IDF for term tt is calculated as:\n",
    "\n",
    "$$IDF(t) = \\log \\left( \\frac{N}{df(t)} \\right)$$\n",
    "\n",
    "\n",
    "When smoothing is applied (i.e., when smooth_idf=True), we add 1 to both the numerator and the denominator as if an extra document was seen containing every term in the collection exactly once:\n",
    "\n",
    "$$IDF(t) = \\log \\left( \\frac{N + 1}{df(t) + 1} \\right)$$\n",
    "\n",
    "This ensures that even terms with zero document frequency (i.e., terms that do not appear in any document) have a non-zero IDF value. By adding 1 to both the numerator and the denominator, we prevent zero divisions and avoid undefined values, thus smoothing the IDF calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40db818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer with smooth_idf True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first        is       one    second       the  \\\n",
       "text 1  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "text 2  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
       "text 3  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "text 4  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "           third      this  \n",
       "text 1  0.000000  0.384085  \n",
       "text 2  0.000000  0.281089  \n",
       "text 3  0.511849  0.267104  \n",
       "text 4  0.000000  0.384085  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(smooth_idf=True)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TfidfVectorizer with smooth_idf True\")\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91703442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer with smooth_idf False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469417</td>\n",
       "      <td>0.617227</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.609532</td>\n",
       "      <td>0.255431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0.532485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223143</td>\n",
       "      <td>0.532485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223143</td>\n",
       "      <td>0.532485</td>\n",
       "      <td>0.223143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469417</td>\n",
       "      <td>0.617227</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first        is       one    second       the  \\\n",
       "text 1  0.000000  0.469417  0.617227  0.364544  0.000000  0.000000  0.364544   \n",
       "text 2  0.000000  0.657827  0.000000  0.255431  0.000000  0.609532  0.255431   \n",
       "text 3  0.532485  0.000000  0.000000  0.223143  0.532485  0.000000  0.223143   \n",
       "text 4  0.000000  0.469417  0.617227  0.364544  0.000000  0.000000  0.364544   \n",
       "\n",
       "           third      this  \n",
       "text 1  0.000000  0.364544  \n",
       "text 2  0.000000  0.255431  \n",
       "text 3  0.532485  0.223143  \n",
       "text 4  0.000000  0.364544  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(smooth_idf=False)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TfidfVectorizer with smooth_idf False\")\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c77483",
   "metadata": {},
   "source": [
    "### Sublinear TF\n",
    "\n",
    "* **When sublinear_tf=True:** sublinear scaling is applied to the TF values. Sublinear scaling applies a logarithmic transformation to the term frequency values, which reduces the impact of very high term frequencies. This transformation helps to normalize the effect of term frequency, preventing terms with very high frequency from dominating the TF-IDF scores.\n",
    "\n",
    "\n",
    "    $$TF(t)transformed= \\left( {1+log⁡(TF(t))} \\right)$$\n",
    "    \n",
    "* **sublinear_tf=False** TF(t)TF(t) is the original term frequency of term tt in the document.\n",
    "\n",
    "This transformation ensures that the TF values are scaled logarithmically, leading to a more balanced representation of term frequencies in the TF-IDF scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbcfae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer with sublinear_tf True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578809</td>\n",
       "      <td>0.302047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first        is       one    second       the  \\\n",
       "text 1  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "text 2  0.000000  0.625527  0.000000  0.302047  0.000000  0.578809  0.302047   \n",
       "text 3  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "text 4  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "           third      this  \n",
       "text 1  0.000000  0.384085  \n",
       "text 2  0.000000  0.302047  \n",
       "text 3  0.511849  0.267104  \n",
       "text 4  0.000000  0.384085  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TfidfVectorizer with sublinear_tf True\")\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10997dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer with sublinear_tf False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 3</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             and  document     first        is       one    second       the  \\\n",
       "text 1  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "text 2  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
       "text 3  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "text 4  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "           third      this  \n",
       "text 1  0.000000  0.384085  \n",
       "text 2  0.000000  0.281089  \n",
       "text 3  0.511849  0.267104  \n",
       "text 4  0.000000  0.384085  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=False)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_dense = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TfidfVectorizer with sublinear_tf False\")\n",
    "pd.DataFrame(data = X_dense, columns=feature_names, index=[\"text 1\", \"text 2\", \"text 3\", \"text 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9db24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
